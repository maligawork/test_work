# Test Project

## 1. Installation
```
git clone https://github.com/maligawork/test_work.git
cd test_work
```

## 2. Setup Environment Conda
```
conda env create -f environment.yml
```

## 3. Run training code

Run training:
```
cd bin
python train.py
```

Resume training:
```
python train.py --experimental-rerun path-to-config.pickle-file
```

## 4. Run test code

Download test_experiments.zip and unzip it in the root directory.
https://drive.google.com/file/d/1yx2Gbo8zDjy0ZI59zPPZO1Vod6XGRsRu/view?usp=share_link

Run inference:
```
cd bin
python test.py --experimental-rerun ../experiments_results/train/train/21-02-2025_12-45-24/.hydra/config.pickle
```


# Решение п.2 задания

Как объединить информацию с двух изображений в архитектуре модели?

### 1. Конкатенация по каналам
Просто объединяем два изображения по каналам.
#### Преимущества:
- Простота реализации (хорошо подходит для baseline модели)
- Можно использовать стандартные архитектуры CNN без модификаций
#### Недостатки:
- Не учитывает, что изображения связаны (модель просто видит два отдельных изображения)
- Может приводить к проблемам с памятью при использовании больших изображений

### 2. Использовать ViT архитектуру
Каждое изображение разбивается на патчи -> объединяем патчи обоих изображений в один общий набор -> получаем эмбединги -> подаем на вход ViT модели -> используем CLS-токен для предсказания.
#### Преимущества:
- Модель может находить сложные зависимости между изображениями
- Учитывает расположение объектов на изображении (что может быть проблемой в п.1)
#### Недостатки:
- Требует больше данных и ресурсов для обучения (в нашем случае это не большая проблема)
- Будет работать медленнее, чем CNN и иметь много параметров

### 3. Использовать сиамскую архитектуру
Используем две идентичные ветви (с одинаковыми весами)-> извлекаем признаки из обоих изображений -> сравниваем признаки -> предсказываем.
#### Преимущества:
- Эффективно используется информация из обоих изображений
- Сеть учится отличать изображения друг от друга, а не просто классифицировать их как в п.1
- Можно использовать предобученные архитектуры CNN для извлечения признаков, а не учить с нуля
- Меньше параметров и операций в модели по сравнению с п.2 (можно конечно взять ViT в качестве backbone, но это излишне)
- Можно разбить архитектуру на две части (backbone и FC слои), что уменьшит количество хранимых параметров при встройке в продакшен
#### Недостатки:
- Реализация чуть сложнее, чем в п.1


# Решение п.3 задания

### 1. Описание структуры проекта
```
project
├── bin - папка с скриптами для обучения и тестирования модели (можно добавить какие-то другие скрипты, например для evaluation, теста baseline модели и тп.)
    ├── train.py - скрипт для обучения модели
    └── test.py - скрипт для тестирования модели
├── configs - папка с конфигурациями для обучения и тестирования модели (в данном проекте слегка избыточная, но в целом хорошая структура, которая позволяет легко менять параметры и модели)
    ├── train.yaml - основная конфигурация для обучения модели
    ├── data - конфигурация для датасета (например, путь к датасету, batch size, input size и тп.)
    ├── model - конфигурация для модели (например, backbone, loss function, metrics и тп.)
    └── hyp - гиперпараметры (оптимизатор, lr scheduler, logging и тп.)
├── pipeline - основная папка описывающая пайплайн
    ├── callbacks - папка с колбэками
    ├── data - папка с генирацией и обработкой данных
    ├── metrics - папка с метриками для оценки моделей
    ├── modules - папка с описанием моделей 
    ├── trainers - папка с тренерами для обучения и тестирования моделей
    └── utils - папка с утилитами 
├── experiments_results - папка с результатами обучения и тестирования моделей
    ...
       ├── experiment_date
          ├── .hydra - хранит основные параметры конфигурации
          ├── checkpoints - хранит checkpointы моделей
          ├── results - хранит результаты обучения и тестирования (0 - означает что это первая видеокарта, 1 - вторая видеокарта и тп.)
          ├── tensorboard_logs - хранит логи обучения и тестирования для визуализации в TensorBoard
├── environment.yml - описание окружения
└── README.md - описание проекта
```

### 2. Описание реализации

Я решил использовать сиамскую архитектуру по причинам, описанным в п.2 задания. Использовал стандартную архитектуру ResNet18 в качестве backbone и добавил пару слоёв FC для предсказания. В целом это самый эффективный и простой способ объединить информацию из двух изображений, который позволяет реализовать быстрый baseline. 

### 3. Описание результатов

Результаты можно посмотреть в папке experiments_results визуализировав логи в TensorBoard и просмотрев результаты тестирования в папке results. Тажке можно подсчитать метрики с помощью скрипта test.py. Метрики стандартные для задачи классификации **accuracy, precision, recall, F1 score, ROC AUC score** и все они максимальные (=1). 

##### Почему так? 

В целом задача достаточно простая, данных можно генерировать сколько угодно (я использовал *num_samples=10000*) для каждого из датасетов. Очевидно, что модель будет вероятно видеть при обучении данные, которые будут генерироваться позже при валидации и тестировании (это не противоречит заданию), но сочетания картинок вероятно все равно будут достаточно разнообразными (дополнительно можно аугментировать данные с помощью поворотов[в целом реализация это предусматривает], но я не стал делать этого, потому что на таком низком разрешении маленький повернутый квадрат становится почти кругом). Второй момент - это уже предобученная модель ResNet18, которая на таком низком разрешении даёт достаточно хорошие результаты практически без обучения + я не стал менять первый слой на одноканальный, чтобы не сбивать уже хорошие веса, получается что остается только обучить FC слои, что также не требует большой сложности.

##### Что можно улучшить?
1. Можно не обучать backbone, а заморозить его веса и обучать только FC слои (вряд ли это сильно ухудшит результаты, но заметно ускорит обучение).
2. Учитывая легкость задачи, можно отказаться от достаточно тяжелого ResNet18 и обучать легкий CNN из нескольких слоев с нуля (будет меньше параметров и операций в модели), использовать одноканальные изображения на входе (будет минимально быстрее).
3. Можно отказаться от FC слоёв и обучать только backbone, а результаты предсказывать по косинусному расстоянию между эмбеддингами.
4. Можно добавить повороты, но для этого нужно будет увеличить минимальный размер квадрата, чтобы он не превращался в круг.



